La comunidad internacional evalúa posibles respuestas a los sistemas armamentísticos autónomos letales, los ‘robots asesinos’, capaces de operar sin instrucciones humanas, entre ellas un eventual código de conducta, un mecanismo de revisión de la tecnología o un instrumento legalmente vinculante.

“Se han abordado los pros y los contras y se ha barajado una gama de opciones políticas, que van desde adoptar una declaración políticamente vinculante, un código de conducta, un mecanismo de revisión continuada de la tecnología y un instrumento legalmente vinculante”, dijo hoy a los medios el embajador de la India ante la Conferencia de Desarme de la ONU, Amandeep Gill.

El diplomático indio también preside el Grupo de Expertos Gubernamentales sobre Sistemas de Armas Autónomos Letales que se reunió del 13 al 17 de noviembre en Ginebra para abordar por primera vez de manera formal en la ONU los retos y las implicaciones éticas, técnicas, legales y militares de los llamados ‘robots asesinos’.

En el encuentro participaron algunos de los 125 Estados parte de la Convención, así como representantes de organizaciones internacionales, de la industria y de la sociedad civil, ONG y académicos.

Gill explicó que de este debate saldrán unas conclusiones y recomendaciones y, si hay consenso, la convocatoria para 2018 de una nueva reunión más larga, de dos semanas, sobre los ‘robots asesinos’.

Es entonces cuando las partes pretenden determinar los rasgos de esta tecnología y los sistemas de armas autónomos letales para llegar a un entendimiento común acerca de “con qué lidiamos”.

Actualmente hay mucha confusión en torno a este concepto y no hay constancia de la existencia de ‘robots asesinos’.

Según numerosos expertos, los avances en el ámbito de la inteligencia artificial permitirán en poco tiempo crear armas, por ejemplo drones, capaces de operar de forma autónoma en el campo de batalla y de tomar decisiones por sí solos sin instrucciones humanas.

Una veintena de países ya ha pedido prohibir esos sistemas, mientras activistas de derechos humanos advierten de que al menos seis Estados están invirtiendo en este tipo de tecnología.

Recientemente más de un centenar de líderes del sector tecnológico alertaron de que los ‘robots asesinos’ pueden convertirse en “armas de terror” y ser utilizadas contra inocentes por parte de “déspotas y terroristas” o pirateadas para emplearlas de forma indeseada.

Gill quiso transmitir un mensaje tranquilizador a la sociedad, al afirmar que “la buena noticia es que los robots no están tomando el control del mundo”.

“Los humanos aún están al mando y continuarán estando en el control, y nos aseguraremos de que así siga siendo”, dijo.

Pidió “no dramatizar este tema” o hablar de él con demasiadas emociones, ya que, resaltó, es una cuestión muy compleja en la que “los países parte de la Convención tienen que hacer su trabajo, yo como presidente y las ONG” por su parte.

Gill quiere por ello que en la próxima cita se trate la temática de la “interfaz humano-máquina”, que se refiere a la interacción de la persona y un programa informático y que en el caso de los “robots asesinos” puede significar seguir o no controlándolos de alguna manera, frenarlos o retirarlos del campo de batalla.

Abordados estos asuntos, añadió, las partes podrán pasar a estudiar posibles respuestas políticas.

(Fuente: EFE)